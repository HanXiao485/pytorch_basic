{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f71f2a9-3357-4e79-9254-4a1c649b79f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e6ba43a-f742-4ff9-8296-e87c039c55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(range(1,51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "552030d6-f03b-4e79-be04-bd715d3bd346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abcb7c52-ddc6-4608-914f-b39d9f184db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.normal(mean=torch.arange(1., 51.), std=torch.arange(1, 0, -0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0761b8ce-22e4-4c84-afa2-a4c03341713e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8342],\n",
       "        [ 1.8010],\n",
       "        [ 2.7628],\n",
       "        [ 2.3609],\n",
       "        [ 4.4612],\n",
       "        [ 6.5179],\n",
       "        [ 5.8828],\n",
       "        [ 8.1877],\n",
       "        [10.4607],\n",
       "        [ 9.0983],\n",
       "        [10.8335],\n",
       "        [10.2430],\n",
       "        [13.7366],\n",
       "        [13.0059],\n",
       "        [15.1466],\n",
       "        [15.9450],\n",
       "        [17.1402],\n",
       "        [17.9228],\n",
       "        [18.2525],\n",
       "        [19.8906],\n",
       "        [20.0821],\n",
       "        [22.8677],\n",
       "        [22.4945],\n",
       "        [24.4458],\n",
       "        [25.5376],\n",
       "        [25.1024],\n",
       "        [27.3246],\n",
       "        [27.8676],\n",
       "        [28.6217],\n",
       "        [30.0895],\n",
       "        [30.9877],\n",
       "        [32.2737],\n",
       "        [33.2966],\n",
       "        [34.2918],\n",
       "        [34.9822],\n",
       "        [36.3678],\n",
       "        [37.1080],\n",
       "        [37.8488],\n",
       "        [39.1045],\n",
       "        [39.7011],\n",
       "        [41.4390],\n",
       "        [41.8650],\n",
       "        [43.0137],\n",
       "        [43.8970],\n",
       "        [44.8647],\n",
       "        [45.8754],\n",
       "        [46.9765],\n",
       "        [48.0550],\n",
       "        [48.9922],\n",
       "        [50.0006]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b03feec-78d7-4739-a053-85b565f515de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1],\n",
       "        [ 2],\n",
       "        [ 3],\n",
       "        [ 4],\n",
       "        [ 5],\n",
       "        [ 6],\n",
       "        [ 7],\n",
       "        [ 8],\n",
       "        [ 9],\n",
       "        [10],\n",
       "        [11],\n",
       "        [12],\n",
       "        [13],\n",
       "        [14],\n",
       "        [15],\n",
       "        [16],\n",
       "        [17],\n",
       "        [18],\n",
       "        [19],\n",
       "        [20],\n",
       "        [21],\n",
       "        [22],\n",
       "        [23],\n",
       "        [24],\n",
       "        [25],\n",
       "        [26],\n",
       "        [27],\n",
       "        [28],\n",
       "        [29],\n",
       "        [30],\n",
       "        [31],\n",
       "        [32],\n",
       "        [33],\n",
       "        [34],\n",
       "        [35],\n",
       "        [36],\n",
       "        [37],\n",
       "        [38],\n",
       "        [39],\n",
       "        [40],\n",
       "        [41],\n",
       "        [42],\n",
       "        [43],\n",
       "        [44],\n",
       "        [45],\n",
       "        [46],\n",
       "        [47],\n",
       "        [48],\n",
       "        [49],\n",
       "        [50]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38383b2e-2b95-4ea4-98a6-d23d56838029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x27d54210b90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.utils.data.TensorDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d060201d-9fda-4f90-a003-0222fbd8bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28904908-aadb-4137-b6bb-a33552e209b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=torch.utils.data.DataLoader(dataset,10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2641dde4-65f0-4f8d-9275-cc6fe6ac8f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([39, 45, 35, 42, 20, 31, 50, 40, 32,  3]),\n",
       " tensor([39.1045, 44.8647, 34.9822, 41.8650, 19.8906, 30.9877, 50.0006, 39.7011,\n",
       "         32.2737,  2.7628])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b91dabe-2127-4bfa-b126-4786c213238f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0b8d14d-65bb-4d18-b9a5-5581db7a4340",
   "metadata": {},
   "source": [
    "## 20240416"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c068ffe6-9ba7-4925-a464-df457b54c573",
   "metadata": {},
   "source": [
    "## 利用类定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d496c125-c7b4-40c1-aeb6-ee63a1b68e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 1])\n",
      "tensor([4, 2])\n",
      "tensor([3])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 自定义 Dataset 类\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "# 创建数据集实例\n",
    "data = [1, 2, 3, 4, 5]\n",
    "dataset = MyDataset(data)\n",
    "\n",
    "# 创建 DataLoader 实例\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 使用 DataLoader 迭代数据\n",
    "for batch in dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55706fb5-47e6-40eb-9f2f-bab7680752c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f26e7d-9b28-4d77-a84e-b48345f13e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理原始异常\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "新异常",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m原始异常\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mValueError\u001b[0m: 原始异常",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m处理原始异常\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m新异常\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 新异常"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    raise ValueError(\"原始异常\")\n",
    "except ValueError as e:\n",
    "    print(\"处理原始异常\")\n",
    "    raise TypeError(\"新异常\") from e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5ba21-399d-445f-817c-9881fb198914",
   "metadata": {},
   "source": [
    "## 创建模型、优化器，并且获取其状态字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b7cf35d-6888-4795-8a22-84c7940abe03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model State Dict:\n",
      "OrderedDict([('weight', tensor([[0.2824]])), ('bias', tensor([0.2067]))])\n",
      "\n",
      "Optimizer State Dict:\n",
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 创建一个简单的神经网络模型和优化器\n",
    "model = nn.Linear(1, 1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 获取模型和优化器的状态字典\n",
    "model_state_dict = model.state_dict()             # .state_dict() 获取模型 状态字典\n",
    "optimizer_state_dict = optimizer.state_dict()     # .state_dict() 获取优化器 状态字典\n",
    "\n",
    "print(\"Model State Dict:\")\n",
    "print(model_state_dict)\n",
    "\n",
    "print(\"\\nOptimizer State Dict:\")\n",
    "print(optimizer_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98323245-7dfa-41d7-8fe7-075f2afaec36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3378647-2fc8-4d15-a332-7282eccbf547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n",
      "\n",
      "DataFrame after dropping column:\n",
      "   B\n",
      "0  4\n",
      "1  5\n",
      "2  6\n",
      "\n",
      "DataFrame after dropping row:\n",
      "   A  B  C\n",
      "1  2  5  8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建一个 DataFrame\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7,  8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 删除列\n",
    "df_drop_col = df.drop(columns=['A', 'C'])\n",
    "\n",
    "# 删除行\n",
    "df_drop_row = df.drop(index=[0, 2])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nDataFrame after dropping column:\")\n",
    "print(df_drop_col)\n",
    "\n",
    "print(\"\\nDataFrame after dropping row:\")\n",
    "print(df_drop_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9dc2f-9903-4e61-9888-1537fc471669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3af1e5b0-7139-4bf5-9a00-cfd517cb99eb",
   "metadata": {},
   "source": [
    "## iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af440224-32ef-43fe-8e73-6b761bddf03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "class MyIterator:\n",
    "    def __init__(self, max_num):\n",
    "        self.max_num = max_num\n",
    "        self.current_num = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_num < self.max_num:\n",
    "            self.current_num += 1\n",
    "            return self.current_num\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "# 使用迭代器对象\n",
    "my_iter = MyIterator(5)\n",
    "for num in my_iter:\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2df4e-c9f6-4d98-94e1-34acca47c572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e47defe5-a9f5-42bd-ad98-baef3e6400d7",
   "metadata": {},
   "source": [
    "# 20240417"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623d3fb9-3ab5-4f55-95b1-e91c584f7deb",
   "metadata": {},
   "source": [
    "## 自定义数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51495807-0dd3-465d-9853-5e81406b1558",
   "metadata": {},
   "source": [
    "### 1 通过torch.utils.data.Dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa24633-77fd-4467-8c22-3e327e0ef939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.CustomDataset'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 示例数据集\n",
    "data = [1, 2, 3, 4, 5]\n",
    "custom_dataset = CustomDataset(data)\n",
    "print(type(custom_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1cbc80c-6bd7-48b0-9b7c-3b34b233db26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(custom_dataset, batch_size=2, shuffle=True)\n",
    "print(type(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b3b4bf-0406-4166-bc29-c05d8adee713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 3])\n",
      "tensor([1, 5])\n",
      "tensor([2])\n"
     ]
    }
   ],
   "source": [
    "for data in data_loader:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33590105-4383-4a2a-acce-25d9a00fba7a",
   "metadata": {},
   "source": [
    "### 2 通过torch.utils.data.TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a51d12-ab48-4655-8a71-22441dadfbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch data:\n",
      "tensor([[5., 6.],\n",
      "        [3., 4.]])\n",
      "Batch labels:\n",
      "tensor([0, 1])\n",
      "Batch data:\n",
      "tensor([[1., 2.]])\n",
      "Batch labels:\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 创建一个简单的数据集\n",
    "data = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "labels = torch.tensor([0, 1, 0])\n",
    "dataset = TensorDataset(data, labels)\n",
    "\n",
    "# 创建一个 DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 迭代 DataLoader 并访问数据\n",
    "for batch_data, batch_labels in dataloader:\n",
    "    print(\"Batch data:\")\n",
    "    print(batch_data)\n",
    "    print(\"Batch labels:\")\n",
    "    print(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043d2de0-7d80-4d38-a018-d5dfc1f255d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bae1d0a-bb72-407e-8868-1c8b015daa10",
   "metadata": {},
   "source": [
    "### 3 one_hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1487d20f-9c17-495e-8e71-6023a34f4917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in d:\\anaconda3\\envs\\han_1\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in d:\\anaconda3\\envs\\han_1\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.2-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB 217.9 kB/s eta 0:00:49\n",
      "   ---------------------------------------- 0.0/10.6 MB 217.9 kB/s eta 0:00:49\n",
      "   ---------------------------------------- 0.1/10.6 MB 297.7 kB/s eta 0:00:36\n",
      "   ---------------------------------------- 0.1/10.6 MB 297.7 kB/s eta 0:00:36\n",
      "   ---------------------------------------- 0.1/10.6 MB 280.5 kB/s eta 0:00:38\n",
      "   ---------------------------------------- 0.1/10.6 MB 328.0 kB/s eta 0:00:33\n",
      "    --------------------------------------- 0.1/10.6 MB 425.3 kB/s eta 0:00:25\n",
      "    --------------------------------------- 0.2/10.6 MB 476.3 kB/s eta 0:00:22\n",
      "    --------------------------------------- 0.2/10.6 MB 497.6 kB/s eta 0:00:21\n",
      "    --------------------------------------- 0.2/10.6 MB 533.8 kB/s eta 0:00:20\n",
      "   - -------------------------------------- 0.3/10.6 MB 584.5 kB/s eta 0:00:18\n",
      "   - -------------------------------------- 0.3/10.6 MB 675.8 kB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.4/10.6 MB 809.9 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.5/10.6 MB 891.2 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.6/10.6 MB 965.4 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.8/10.6 MB 1.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 0.9/10.6 MB 1.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.1/10.6 MB 1.5 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 1.3/10.6 MB 1.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.6/10.6 MB 2.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.9/10.6 MB 2.3 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.2/10.6 MB 2.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.6/10.6 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.5/10.6 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.0/10.6 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.5/10.6 MB 4.3 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.9/10.6 MB 4.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.3/10.6 MB 4.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.9/10.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.4/10.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.9/10.6 MB 5.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.6 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.9/10.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.4/10.6 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.7/10.6 MB 6.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.9/10.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.4/10.6 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.9/10.6 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.6 MB 8.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 301.2/301.2 kB 9.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.0 scikit-learn-1.4.2 threadpoolctl-3.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e16a31b-40c3-418f-9d24-30eaf1ad2fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded data:\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# 创建一组分类变量\n",
    "data = np.array([['cat'], ['cat'], ['dog'], ['bird'], ['cat'], ['bird'], ['bird'], ['bird']])\n",
    "\n",
    "# 创建一个 OneHotEncoder 实例\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# 对数据进行编码\n",
    "onehot_encoded = encoder.fit_transform(data)\n",
    "\n",
    "print(\"Encoded data:\")\n",
    "print(onehot_encoded)\n",
    "print(type(onehot_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9eb2648-a6d2-44c4-83f7-5a541dfc6435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28fcb2ea-92de-485d-b98b-db8cc765c2a9",
   "metadata": {},
   "source": [
    "### 5 os.path.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d19ea78-ea0c-443b-acaf-b6a90abdea58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path/to/directory\\file.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path1 = 'path/to/directory'\n",
    "path2 = 'file.txt'\n",
    "\n",
    "full_path = os.path.join(path1, path2)\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af6f02-5274-4c17-9fd4-3824e1094a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd565a-b69b-4d0e-ad93-ed2dc685407b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea954a45-44bd-4e5b-a552-04cd5c4e18ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "125af898-4065-46b5-bf1a-a35e9b09928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.model = nn.Sequential(        #nn.Sequential\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# 创建一个 MyModel 实例\n",
    "model = MyModel()\n",
    "\n",
    "# 输出模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e033e4c-c5e9-4894-b243-bbbaf66363c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0311,  0.0086,  0.0348,  ..., -0.0286, -0.0039,  0.0096],\n",
       "         [-0.0225, -0.0265, -0.0254,  ...,  0.0160,  0.0330, -0.0158],\n",
       "         [ 0.0260,  0.0025,  0.0085,  ..., -0.0037,  0.0250,  0.0149],\n",
       "         ...,\n",
       "         [ 0.0355, -0.0268, -0.0008,  ..., -0.0003, -0.0221,  0.0286],\n",
       "         [-0.0290, -0.0149, -0.0263,  ..., -0.0232,  0.0115,  0.0147],\n",
       "         [-0.0356, -0.0297, -0.0350,  ..., -0.0264,  0.0057,  0.0072]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0069,  0.0282,  0.0015, -0.0288,  0.0237, -0.0237,  0.0041, -0.0039,\n",
       "          0.0348,  0.0275,  0.0284,  0.0336, -0.0236,  0.0221,  0.0293,  0.0205,\n",
       "          0.0071, -0.0102,  0.0290, -0.0294, -0.0165,  0.0252, -0.0220,  0.0103,\n",
       "          0.0084, -0.0139, -0.0074,  0.0287, -0.0205, -0.0035,  0.0085, -0.0137,\n",
       "         -0.0115, -0.0178,  0.0150,  0.0304, -0.0028,  0.0292,  0.0265,  0.0020,\n",
       "         -0.0116,  0.0157,  0.0217,  0.0043,  0.0261, -0.0092, -0.0038,  0.0073,\n",
       "          0.0278, -0.0090,  0.0329, -0.0339, -0.0185,  0.0202,  0.0171,  0.0302,\n",
       "          0.0314, -0.0112,  0.0120, -0.0205, -0.0274,  0.0143,  0.0054,  0.0311,\n",
       "         -0.0251,  0.0016,  0.0174, -0.0327, -0.0226, -0.0271,  0.0314, -0.0053,\n",
       "         -0.0261, -0.0282,  0.0221, -0.0061,  0.0052,  0.0306,  0.0045,  0.0026,\n",
       "         -0.0135, -0.0050, -0.0210,  0.0303,  0.0219,  0.0031,  0.0098,  0.0196,\n",
       "          0.0084, -0.0020, -0.0312, -0.0021, -0.0261, -0.0170,  0.0172, -0.0074,\n",
       "         -0.0339, -0.0301,  0.0332, -0.0316, -0.0014, -0.0267, -0.0296, -0.0206,\n",
       "         -0.0096,  0.0249, -0.0318,  0.0331,  0.0327,  0.0186,  0.0160,  0.0276,\n",
       "         -0.0254,  0.0124, -0.0320,  0.0192,  0.0086,  0.0244, -0.0107, -0.0083,\n",
       "         -0.0339, -0.0053, -0.0263, -0.0279,  0.0341,  0.0034,  0.0349, -0.0081,\n",
       "          0.0126, -0.0150,  0.0302, -0.0246,  0.0061,  0.0074,  0.0315,  0.0237,\n",
       "         -0.0213, -0.0070,  0.0109,  0.0169,  0.0075,  0.0173, -0.0240,  0.0343,\n",
       "         -0.0230,  0.0085, -0.0021,  0.0280,  0.0302,  0.0134, -0.0076,  0.0013,\n",
       "          0.0013, -0.0276,  0.0119, -0.0354, -0.0111, -0.0143,  0.0240,  0.0021,\n",
       "          0.0023,  0.0260, -0.0305,  0.0125,  0.0081,  0.0081,  0.0052,  0.0356,\n",
       "          0.0134, -0.0125,  0.0112,  0.0068,  0.0058,  0.0016,  0.0075, -0.0102,\n",
       "         -0.0016,  0.0223,  0.0180, -0.0159,  0.0318,  0.0208,  0.0227,  0.0121,\n",
       "          0.0040, -0.0116, -0.0044,  0.0117,  0.0064,  0.0336,  0.0233,  0.0281,\n",
       "          0.0313,  0.0306, -0.0256,  0.0082,  0.0242, -0.0193,  0.0091,  0.0148,\n",
       "          0.0350,  0.0240, -0.0030, -0.0307,  0.0252,  0.0226,  0.0059,  0.0111,\n",
       "         -0.0291, -0.0031, -0.0113, -0.0236, -0.0185, -0.0318, -0.0141,  0.0062,\n",
       "         -0.0212,  0.0276, -0.0114,  0.0014,  0.0324, -0.0053,  0.0153,  0.0279,\n",
       "          0.0178, -0.0199, -0.0054,  0.0097, -0.0165, -0.0205, -0.0128, -0.0318,\n",
       "          0.0089,  0.0001, -0.0196, -0.0181,  0.0159,  0.0128, -0.0043,  0.0111,\n",
       "          0.0097, -0.0037, -0.0170, -0.0210,  0.0197, -0.0310,  0.0098,  0.0357,\n",
       "         -0.0140, -0.0196,  0.0252,  0.0262, -0.0032, -0.0119, -0.0326,  0.0030],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0291,  0.0452, -0.0129,  ..., -0.0534, -0.0496,  0.0263],\n",
       "         [ 0.0320,  0.0037, -0.0189,  ..., -0.0378,  0.0177,  0.0520],\n",
       "         [ 0.0095,  0.0045, -0.0564,  ...,  0.0088,  0.0301,  0.0406],\n",
       "         ...,\n",
       "         [-0.0014, -0.0374,  0.0106,  ..., -0.0455,  0.0575, -0.0384],\n",
       "         [-0.0397,  0.0432, -0.0426,  ..., -0.0229, -0.0571,  0.0077],\n",
       "         [ 0.0169, -0.0054, -0.0255,  ..., -0.0331, -0.0047, -0.0585]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0208, -0.0589, -0.0546, -0.0520, -0.0372, -0.0184, -0.0198, -0.0601,\n",
       "          0.0570,  0.0148], requires_grad=True)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0fe4aa-c102-42a0-96fa-9158f3ff40a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
